<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <title></title>
  <style type="text/css">code{white-space: pre;}</style>
  <link rel="stylesheet" href="../css.github.css" type="text/css" />
</head>
<body>
<h1 id="cost-function">Cost Function</h1>
<hr />
<h4 id="linear-regression-cost-function">Linear Regression Cost Function</h4>
<p><span class="math inline">$J(\theta)= \frac{1}{m} \sum_{i=0}^m \frac{1}{2}(h_\theta(x)-y)^2$</span></p>
<p><span class="math inline">$Cost(h_\theta(x),y) = \frac{1}{2} (h_\theta(x) - y)^2$</span></p>
<p><span class="math inline">$h_\theta(x) = \frac{1}{1+\mathrm{e}^{-\theta x}}$</span>  :  sigmoid(logistic) functin</p>
<p>In sigmoid function, Cost function will be <strong>non-convex</strong>.<br />
we want convex cost function</p>
<h4 id="logistic-regression-cost-function">Logistic Regression Cost Function</h4>
[J()=  <em>{i=1}^m Cost(h</em>(x^{(i)}),y{(i)})\ [Cost(h_(x),y) =

<p>]</p>
<div class="figure">
<img src="image/sigmoid_regression_y1.png" />

</div>
<p><br/> <br/> <span class="math inline"><em>C</em><em>o</em><em>s</em><em>t</em> = 0 <em>i</em><em>f</em> <em>y</em> = 1, <em>h</em><sub><em>θ</em></sub>(<em>x</em>)=1</span><br />
<span class="math inline"><em>B</em><em>u</em><em>t</em> <em>a</em><em>s</em> <em>h</em><sub><em>θ</em></sub>(<em>x</em>)→0,  <em>C</em><em>o</em><em>s</em><em>t</em> → ∞</span></p>
<ul>
<li>Capture intuition that if <span class="math inline"><em>h</em><sub><em>θ</em></sub>(<em>x</em>)=0</span>, (predict P(<span class="math inline"><em>y</em> = 1|<em>x</em>; <em>θ</em></span>) = 0)<br />
but y = 1 we'll penalize learning algorithm by a very Cost</li>
</ul>
<div class="figure">
<img src="image/sigmoid_regression_y0.png" />

</div>
<p><span class="math inline"><em>C</em><em>o</em><em>s</em><em>t</em> = 0 <em>i</em><em>f</em> <em>y</em> = 0, <em>h</em><sub><em>θ</em></sub>(<em>x</em>)=0</span><br />
<span class="math inline"><em>B</em><em>u</em><em>t</em> <em>a</em><em>s</em> <em>h</em><sub><em>θ</em></sub>(<em>x</em>)→1,  <em>C</em><em>o</em><em>s</em><em>t</em> → ∞</span><br />
<br/></p>
<ul>
<li>Writing the cost function in this way guarantees that J(<span class="math inline"><em>θ</em></span>) is convex for logistic regression</li>
</ul>
</body>
</html>
